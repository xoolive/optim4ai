# Optimisation for Machine Learning

[« Previous](../2_gradient) \| [Home ↑](../) \| [Next »](../4_linear)

This section will bring the optimisation topics we addressed with [gradient descent methods](../2_gradient), to Machine Learning and the training of neural networks. To date, there are two most widespread ML libraries for Python, both based on similar concepts: [TensorFlow](https://www.tensorflow.org/) and [PyTorch](https://pytorch.org/).

We will focus here on PyTorch and look into how the library addresses optimisation with particular structures called _tensors_. We focus in the whole section on optimisation problems, and leave neural networks aside.

|     | Topics                                             |
| --- | -------------------------------------------------- |
| 3.1 | [Introduction to tensors in PyTorch](introduction) |
| 3.2 | [Automatic differentation](autograd)               |
| 3.3 | [Optimisers in PyTorch](optimise)                  |
| 3.4 | [Exercice: Linear regression](exercice)            |

The notebook producing these pages is available on the GitHub page, but focus on reading here: blindly executing cells may only distract you from the main content.
