{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f21f5843-8b96-4ef8-8b37-388b18823a61"
    }
   },
   "source": [
    "# Gradient descent methods\n",
    "\n",
    "(Notebook prepared by [Emmanuel Rachelson](https://github.com/erachelson/))\n",
    "\n",
    "In this section, we concentrate on finding the minimum of a given differentiable function $f$. Try to keep on mind the general illustration from section 1 to keep track of why we do this.\n",
    "\n",
    "In order to make things didactic and graphical, we shall work on functions from $\\mathbb{R}^2$ to $\\mathbb{R}$, which can be easily plotted (either as surfaces in 3D or as contour plots in 2D).\n",
    "\n",
    "##Â 1. Descent algorithms\n",
    "\n",
    "Descent algorithms define a sequence of steps \"rolling down\" the function's surface (similarly to how water would flow down from a mountain), that is a sequence of points $x_k$ of decreasing value $f(x_k)$. To construct this sequence, one defines at each step a descent direction $d_k$ and a descent step $\\alpha_k$. The next point in the sequence is thus $x_{k+1} = x_k + \\alpha_k d_k$.\n",
    "\n",
    "Since the gradient $\\nabla f$ of $f$ indicates the steepest ascent direction, $-\\nabla f$ is a descent direction, hence the name **gradient descent**.\n",
    "\n",
    "Let's illustrate that. You don't need to read the full formula of the function below, but for your curiosity, it is built as follows:\n",
    "\\begin{align}\n",
    "&(x'_0, x'_1) = rotate_{\\pi/6}(x_0,x_1)\\\\\n",
    "&g(z_0,z_1) = \\left(a_4 z_0^4 + a_3 z_0^3 + a_2 z_0^2 + a_1 z_0 + a_0 \\right) \\left( b_2 z_1^2 + b_1 z_1 + b_0 \\right)\\\\\n",
    "&f(x_0,x_1) = g\\left(rotate_{\\pi/6} \\left(x_0,x_1\\right)\\right)\\\\\n",
    "&\\textrm{with }[a_4, a_3, a_2, a_1, a_0] = [0.019217, 0.013158, -0.423455, -0.247614, 4.]\\\\\n",
    "&\\textrm{and }[b_2, b_1, b_0] = [0.1, 0., 0.1]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:24:04.907273Z",
     "start_time": "2019-02-15T10:24:04.894618Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    a = np.pi / 6.0\n",
    "    c = np.cos(a)\n",
    "    s = np.sin(a)\n",
    "    xx = c * x[0] + s * x[1]\n",
    "    yy = -s * x[0] + c * x[1]\n",
    "    p = np.poly1d(\n",
    "        [\n",
    "            0.019217057452351031,\n",
    "            0.013158736688148412,\n",
    "            -0.42345571095569301,\n",
    "            -0.24761472187941180,\n",
    "            4.0,\n",
    "        ]\n",
    "    )\n",
    "    q = np.poly1d([0.1, 0.0, 0.1])\n",
    "    \n",
    "    return p(xx) * q(yy)\n",
    "\n",
    "\n",
    "def func_der(x):\n",
    "    a = np.pi / 6.0\n",
    "    c = np.cos(a)\n",
    "    s = np.sin(a)\n",
    "    xx = c * x[0] + s * x[1]\n",
    "    yy = -s * x[0] + c * x[1]\n",
    "    p = np.poly1d(\n",
    "        [\n",
    "            0.019217057452351031,\n",
    "            0.013158736688148412,\n",
    "            -0.42345571095569301,\n",
    "            -0.24761472187941180,\n",
    "            4.0,\n",
    "        ]\n",
    "    )\n",
    "    pp = np.polyder(p)\n",
    "    q = np.poly1d([0.1, 0.0, 0.1])\n",
    "    qq = np.polyder(q)\n",
    "    grad0 = c * pp(xx) * q(yy) - s * qq(yy) * p(xx)\n",
    "    grad1 = s * pp(xx) * q(yy) + c * qq(yy) * p(xx)\n",
    "    \n",
    "    return np.array([grad0, grad1]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first plot this function. Again, you don't need a deep understanding of the plotting functions below.\n",
    "- The first one plots a function $f$ in 3D;\n",
    "- The second one plots the contour levels of function $f$ in 2D, with several options to plot the function's gradient in specific points.\n",
    "\n",
    "An example is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:24:10.980812Z",
     "start_time": "2019-02-15T10:24:10.787381Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def plot_3d_func(f, X0, X1):\n",
    "    \"\"\"Plots function f over the grid of X0 and X1 arguments.\n",
    "    X0 and X1 should be numpy arrays.\n",
    "    \"\"\"\n",
    "    X = np.meshgrid(X0, X1)\n",
    "    Z = f(X)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection=\"3d\"))\n",
    "    surf = ax.plot_surface(\n",
    "        X[0],\n",
    "        X[1],\n",
    "        Z,\n",
    "        rstride=1,\n",
    "        cstride=1,\n",
    "        cmap=cm.coolwarm,\n",
    "        linewidth=0,\n",
    "        antialiased=False,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels() + ax.get_zticklabels():\n",
    "        label.set_fontsize(\"large\")\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_contours_func(\n",
    "    f,\n",
    "    X0,\n",
    "    X1,\n",
    "    levels=np.array([]),\n",
    "    xp=np.empty((2, 0)),\n",
    "    plot_line=False,\n",
    "    f_der=None,\n",
    "    add_levels=True,\n",
    "):\n",
    "    \"\"\"Contour plot of function f.\n",
    "\n",
    "    - X0 and X1 should be numpy arrays defining a grid over which the contour\n",
    "      plot will be drawn.\n",
    "    - levels should be a numpy array providing user-defined contour levels\n",
    "      (otherwise, 10 regularly spaced levels are generated)\n",
    "    - xp should be a (2,n)-numpy array of (x0,x1)-coordinates for additional\n",
    "      points to plot on the graph\n",
    "    - plot_line indicates whether a line should be plotted between the xp points\n",
    "    - f_der should be a function returning the derivative of f when evaluated in\n",
    "      (x0,x1). It is used to plot the gradient in xp.\n",
    "      If f_der=None no derivatives will be plotted\n",
    "    - add_levels indicates whether to add the contour levels for the xp points\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.meshgrid(X0, X1)\n",
    "    Z = f(X)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    if np.equal(len(levels), 0):\n",
    "        levels = np.arange(np.min(Z), np.max(Z), (np.max(Z) - np.min(Z)) / 10.0)\n",
    "\n",
    "    if np.not_equal(xp.shape[1], 0):\n",
    "        z = f(xp)\n",
    "        if add_levels:\n",
    "            levels = np.append(levels, z)\n",
    "        ax.scatter(\n",
    "            xp[0, :],\n",
    "            xp[1, :],\n",
    "            cmap=cm.autumn,\n",
    "            c=-np.arange(xp.shape[1]),\n",
    "            edgecolors=\"black\",\n",
    "        )\n",
    "        if plot_line:\n",
    "            ax.plot(xp[0, :], xp[1, :])\n",
    "        if np.not_equal(f_der, None):\n",
    "            grad = f_der(xp)\n",
    "            ax.quiver(xp[0, :], xp[1, :], grad[:, 0], grad[:, 1])\n",
    "\n",
    "    levels = np.sort(levels)\n",
    "    cont = ax.contour(X[0], X[1], Z, levels)\n",
    "    ax.clabel(cont, cont.levels, inline=True, fontsize=10)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def clean_axis(ax, center=(0, 0)):\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_color(\"#bab0ac\")\n",
    "    ax.spines[\"left\"].set_color(\"#bab0ac\")\n",
    "\n",
    "    if center is not None:\n",
    "        ax.spines[\"bottom\"].set_position((\"data\", center[1]))\n",
    "        ax.spines[\"left\"].set_position((\"data\", center[0]))\n",
    "\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontsize(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:24:17.650890Z",
     "start_time": "2019-02-15T10:24:14.996593Z"
    }
   },
   "outputs": [],
   "source": [
    "X0 = np.arange(-6, 6, 0.1)\n",
    "X1 = np.arange(-6, 6, 0.1)\n",
    "xd = np.array([[4.0, 3.0, 4.0], [1.5, -0.4, -0.4]])\n",
    "levels = np.array([0.15, 0.2, 0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "\n",
    "fig, ax = plot_3d_func(func, X0, X1)\n",
    "fig, ax = plot_contours_func(func, X0, X1, levels, xp=xd, f_der=func_der)\n",
    "ax.set_xlim((-7, 7))\n",
    "ax.set_ylim((-7, 7))\n",
    "clean_axis(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradient descent with fixed step size\n",
    "\n",
    "Let's take a starting point $x_0$ and write a gradient descent procedure that build the sequence of points $x_{k+1} = x_k + \\alpha_k d_k$ with $d_k = -\\dfrac{\\nabla_x f(x_k)}{\\|\\nabla_x f(x_k)\\|}$ (that is a unit vector in the opposite direction of the gradient) and a fixed step size $\\alpha_k$.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b>\n",
    "<ul>\n",
    "<li> Write an algorithm that starts in $(-5,-4)$ and uses gradient descent on the `func` function defined above, with fixed-length steps of length $\\alpha = 0.1$, for 20 steps (if you need to compute the norm of a vector, use [`np.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)).\n",
    "<li> Use `plot_contours_func` to plot the sequence of points obtained.\n",
    "<li> Did the algorithm find the minimum? Were there enough steps? Increase the number of steps until you reach a vicinity of the minimum.\n",
    "<li> What are the coordinates of this minimum? What is the value of $f$ there? Is this a local or a global minimum?\n",
    "<li> How far do you get from the true minimum?\n",
    "<li> Restart your algorithm at $(4,-4)$, do you obtain the same result?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:24:34.603470Z",
     "start_time": "2019-02-15T10:24:34.271924Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/code1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the gradient's norm in $x$ is the steepest increase rate of the function in $x$. So as long as this norm is non-zero, it means we can still move up or down the function's surface by following the gradient's direction. Conversely, if the gradient becomes zero, it means we have reached a \"flat\" area in the function's surface, which is likely to be a (local) minimum.\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>Exercice:</b>\n",
    "Copy-paste your code from the previous cells in the cell below to modify it. We'll work from the initial point $(x_0,x_1)=(-5,-4)$ in this exercice.\n",
    "<ul>\n",
    "<li> Is there a better way to stop the algorithm than a predefined number of steps? For example using the gradient's norm?\n",
    "<li> Plot the evolution of the gradient's norm (actually you'll see it's clearer to plot the [log](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html) of the gradient's norm) along the 100 first iterations. Is the norm of the gradient always a good way to control the algorithm's stopping? What happens after (around) the 34th iteration?\n",
    "<li> Plot the sequence of points after iteration 34 by using `plot_contours_func` on the $[-3.05,-2.9]\\times[-1.8,-1.6]$ domain.\n",
    "<li> Also plot the (log of the) value of the objective function after iteration 34.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:24:52.402971Z",
     "start_time": "2019-02-15T10:24:51.528019Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/code2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, depending on the value of the threshold we put on the gradient's norm, the algorithm does not terminate. In all cases, fixed-step sizes do not allow us to reach the local minimum but rather oscillate around it. So it seems we need adaptive, decreasing step-sizes. Any ideas as to what values we should pick for the step-size?\n",
    "\n",
    "## 3. A first attempt at adaptive step sizes\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>Exercice:</b> Try implementing a step-size equal to the gradient's norm (again, copy-paste your code from the previous cells to avoid rewriting everything).\n",
    "<ul>\n",
    "<li> Stop the algorithm when the gradient's norm falls below $0.001$\n",
    "<li> How many iterations until convergence?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:25:08.787666Z",
     "start_time": "2019-02-15T10:25:08.103400Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/code3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So apparently, taking a step length proportional to the gradient seems like a good idea. It makes sense intuitively since the norm of the gradient indicates how steep the function is locally, so, the steepest the surface, the biggest the step we can expect to make.<br>\n",
    "<br>\n",
    "However, this intuition can be proven very (very) wrong! In particular, taking a step size equal to the gradient's norm can be catastrophic. To convince yourself, consider the function $f(x)=10\\cos(x)$ on the $[0,2\\pi$] domain and check below what happens on the first step of gradient descent from $x=\\pi/2$. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:25:20.560958Z",
     "start_time": "2019-02-15T10:25:20.374529Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(0, 4 * np.pi, 0.01)\n",
    "Z = 10.0 * np.cos(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "clean_axis(ax)\n",
    "\n",
    "ax.plot(X, Z)\n",
    "x0 = np.pi / 2.0\n",
    "val0 = 10.0 * np.cos(x0)\n",
    "ax.plot(x0, 0.0, \"ro\")\n",
    "grad0 = -10.0 * np.sin(x0)\n",
    "x1 = x0 - grad0\n",
    "val1 = 10.0 * np.cos(x1)\n",
    "ax.arrow(x0, 0.0, -grad0, 0.0, head_width=0.5, length_includes_head=True)\n",
    "ax.plot(x1, 0.0, \"ro\")\n",
    "\n",
    "print(\"First point x0:\", x0)\n",
    "print(\"Gradient in x0:\", grad0)\n",
    "print(\"Second point x1=x0-grad0:\", x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Line search\n",
    "\n",
    "So the gradient gives the steepest descent direction locally but this does not give any reliable information as to the best step size. We learn from this that the step size needs to adapt to the actual function in order for the sequence $f(x_k)$ to actually be decreasing. This is generally done via **line search**. Once a descent direction $d_k$ has been chosen in $x_k$, line search consists in defining the univariate function $g(\\alpha)=f(x_k+\\alpha\\cdot d_k)$ and minimizing this function. Then, the found value for $\\alpha$ is used as $\\alpha_k$ and the process is repeated from $x_{k+1}=x_{k} + \\alpha_k d_k$.<br>\n",
    "<br>\n",
    "The minimization of the scalar function $g$ can be done in a number of ways:\n",
    "<ul>\n",
    "<li> If $g'(\\alpha)=0$ can be easily solved analytically, then it provides a series of candidates for a minimum. \n",
    "<li> Interpolation methods such as Cubic interpolation, Quadratic interpolation (Brent method) or the Golden section method (all left to your curiosity), that do not require the knowledge of an analytical form of $g'$ can be used to narrow down a minimum.\n",
    "</ul>\n",
    "\n",
    "Fortunately for us, `scipy.optimize` provides a [`minimize_scalar`](https://docs.scipy.org/doc/scipy-0.17.1/reference/generated/scipy.optimize.minimize_scalar.html) function that performs this tedious line search for us.\n",
    "\n",
    "Those interested in going further on the topic of step size selection in descent methods can check the following advanced topics (do that later if you are curious, or you probably won't have time to finish this notebook):\n",
    "<ul>\n",
    "<li> Armijo rule and Wolfe conditions\n",
    "<li> Goldstein rule\n",
    "<li> Robbins-Monro stochastic approximation\n",
    "</ul>\n",
    "\n",
    "Before going any further, let us recall an important property. With the line search procedure we just introduced, two successive descent directions are necessarily orthogonal. Why? Simply because if $d_{k+1}$ was not orthogonal to $d_k$, that would mean there is a component of $d_{k+1}$ along $d_k$, which would mean that in $x_{k+1}$, it would still be possible to decrease $f$ just by moving along the $d_k$ direction, but this is obviously impossible since $x_{k+1}$ is the minimum of $f(x_k+\\alpha\\cdot d_k)$. So $d_{k+1}$ is necessarily orthogonal to $d_k$.<br>\n",
    "<br>\n",
    "Note that, in dimension 2, that leaves little choice for the direction $d_{k+1}$ given $d_k$. But in higher dimensions, there is an infinity of unit vectors that are orthogonal to $d_k$, so what this property says really is just that two successive descent directions are orthogonal and nothing else.\n",
    "<div class=\"alert alert-warning\"> <b>Exercice:</b> Just take a minute to make sure you understood this property.<br>\n",
    "</div>\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b><br>\n",
    "Now, reuse your previous code to write a descent method where the descent direction is the normalized gradient and the step size is found by line search.<br>\n",
    "<ul>\n",
    "<li> Can you confirm the above property (graphically)?\n",
    "<li> How many steps until convergence?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:25:44.211158Z",
     "start_time": "2019-02-15T10:25:43.414816Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/code4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice the orthogonal descent directions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convexity\n",
    "\n",
    "Let's take a step back and consider the general question of finding minimas of differentiable functions. So far, what we have intuitively done corresponds to saying that if we roll down the function's surface in the opposite direction of the gradient, we might end up in a zero-gradient point that is a local minimum.\n",
    "\n",
    "We could do that precisely because our functions were differentiable; their gradient exists.\n",
    "\n",
    "But the reverse implication is not true: zero-gradient points are not necessarily minimas! Consider the two following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:26:05.497495Z",
     "start_time": "2019-02-15T10:26:04.602148Z"
    }
   },
   "outputs": [],
   "source": [
    "X0 = np.arange(-1.0, 1.0, 0.05)\n",
    "X1 = np.arange(-1.0, 1.0, 0.05)\n",
    "X = np.meshgrid(X0, X1)\n",
    "Z = -X[0] * X[0] - X[1] * X[1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection=\"3d\"))\n",
    "surf = ax.plot_surface(\n",
    "    X[0],\n",
    "    X[1],\n",
    "    Z,\n",
    "    rstride=1,\n",
    "    cstride=1,\n",
    "    cmap=cm.coolwarm,\n",
    "    linewidth=0,\n",
    "    antialiased=False,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "\n",
    "clean_axis(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:26:05.497495Z",
     "start_time": "2019-02-15T10:26:04.602148Z"
    }
   },
   "outputs": [],
   "source": [
    "Z = -X[0] * X[0] * X[0] - X[1] * X[1] * X[1]\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection=\"3d\"))\n",
    "\n",
    "surf = ax.plot_surface(\n",
    "    X[0],\n",
    "    X[1],\n",
    "    Z,\n",
    "    rstride=1,\n",
    "    cstride=1,\n",
    "    cmap=cm.coolwarm,\n",
    "    linewidth=0,\n",
    "    antialiased=False,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "\n",
    "clean_axis(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both these functions have a null gradient in $(0,0)$ but neither have a minimum in $(0,0)$.\n",
    "\n",
    "So $\\hat{x}$ is a minimum $\\Rightarrow$ $\\nabla_x f(\\hat{x}) = 0$ is true but the reverse implication is false.\n",
    "\n",
    "Take a point $x$ where the surface is flat (with a zero gradient). To guarantee that this point is a (local) minimum we need to guarantee that the fonction is (locally) **convex** around this point. Technically, that means that for any two points $y$ and $z$, if we draw a line between them, the function will actually sit below that line. Formally:\n",
    "$$f\\textrm{ is convex }\\Leftrightarrow \\forall (y,z)\\in\\mathbb{R}^n, \\lambda \\in [0,1], f(\\lambda y + (1-\\lambda) z) \\leq \\lambda f(y) + (1-\\lambda) f(z)$$\n",
    "\n",
    "Let's link that with the gradient. A zero gradient means a flat surface, not a minimum. What we were missing before is the fact that the surface goes up when we move away from the minimum. In other words, when we move away from a minimum (in *any* direction), the slope of the function must increase. This means that the derivative of the gradient must be positive. But the gradient is a vector, so its derivative is a matrix. The gradient's derivative is called the **Hessian matrix**. It is written:\n",
    "$$H_f(x) = \\nabla_x^2 f(x) = \\left[Â \\begin{array}{ccc}\n",
    "\\frac{\\partial^2 f}{\\partial x_0^2}(x) & \\cdots & \\frac{\\partial^2 f}{\\partial x_0Â \\partial x_n}(x)\\\\\n",
    "\\vdots & \\ddots & \\vdotsÂ \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_0 \\partial x_n}(x) & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}(x)\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "And we have the equivalence:\n",
    "$$H_f(x)\\textrm{ is a positive definite matrix} \\Leftrightarrow f\\textrm{ in convex in }x$$\n",
    "\n",
    "We say that a function is strictly convex in $x$ if $H_f(s)$ is positive definite. If it is only postive semi-definite, the function is only convex (not strictly). What does that mean?\n",
    "\n",
    "Recall that a matrix $A$ is positive iff $\\forall x\\in\\mathbb{R}^n, x^T A x \\geq 0$. It is equivalent to say that a matrix is positive and that its eigen-values are strictly positive. On the other hand, the Hessian's elements indicate how fast the gradient's components increase when we slightly move away from $x$ in a given direction. So saying that the Hessian is positive is equivalent to saying that its eigen-values are all positive, which corresponds in turn to saying that the gradient increases, whatever the direction we take to move away from $x$. In the end, $H_f(x)>0$ is a very natural definition of convexity.\n",
    "\n",
    "In particular, if the Hessian is only positive semi-definite, that means some eigen-values can be zero, which means that the gradient does not increase nor decrease in the directions of the corresponding eigen-vectors. In this case, the function is not strictly convex, just convex.\n",
    "\n",
    "Similarly, if $f$ is convex in all possible $x$, we say it is globally convex.\n",
    "\n",
    "Why did we go through all this?\n",
    "1. First because it is important to formalize what convexity is, both geometrically (through the definition above: the function between $y$ and $z$ sits below the line that connects $f(y)$ and $f(z)$) and analytically (the Hessian is positive definite in all $x$).\n",
    "2. Because we will now use this characterization of convexity to look at the function's shape (and not only the gradient) to improve our gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adapting the descent directions to the function's conditioning\n",
    "\n",
    "Let us now take a look at a last issue in descent methods. In the previous example, you may have noticed the sequence of points keeps bouncing off the \"walls\" of the surface, moving in consecutive orthogonal directions. That would actually be perfect if these \"walls\" were circular because in that case the first gradient would directly point to the minimum. Unfortunately, in real life, functions are rarely so well-behaved. Still, wouldn't it be nice to have a series of descent directions that automatically adapt to the local shape of the function?\n",
    "\n",
    "Formally, the local *conditioning* of a convex function in $x$ is the ratio $\\frac{M}{m}$ between the biggest and the smallest eigen-value of its Hessian matrix $H=\\nabla^2 f(x)$ in $x$. Graphically, the conditioning measures how \"well-behaved\" is the function for gradient descent (that is how \"circular\" are the contour lines). A well-conditioned function locally looks like a circular crater (and the conditioning is close to 1), while an ill-conditioned function locally looks like the grand canyon (and the conditioning is large).\n",
    "\n",
    "Let's illustrate this on the two functions $f_0(x_0,x_1) = x_0^2+x_1^2$ and $f_1(x_0,x_1) = x_0^2+10x_1^2$.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Exercice:</b>\n",
    "<ul>\n",
    "<li> What are the Hessian matrices of $f_1$ and $f_2$? Do these matrices depend on $x$?\n",
    "<li> What is the conditioning of $f_1$? And $f_2$?\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Let's illustrate that graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:26:33.293173Z",
     "start_time": "2019-02-15T10:26:32.756479Z"
    }
   },
   "outputs": [],
   "source": [
    "def func0(x):\n",
    "    return x[0] * x[0] + x[1] * x[1]\n",
    "\n",
    "\n",
    "def func1(x):\n",
    "    return x[0] * x[0] + 10 * x[1] * x[1]\n",
    "\n",
    "\n",
    "X0 = np.arange(-1, 1, 0.05)\n",
    "X1 = np.arange(-1, 1, 0.05)\n",
    "\n",
    "fig, ax = plot_contours_func(func0, X0, X1)\n",
    "clean_axis(ax)\n",
    "\n",
    "fig, ax = plot_contours_func(func1, X0, X1)\n",
    "clean_axis(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, changing the basis vectors (that is, changing the coordinates system) used to describe our function, changes its conditioning. Recall old memories of linear algebra: if you change the coordinate systems by moving from the canonical basis to the basis formed by the eigen-vectors of the Hessian matrix, then, locally, you get a perfect conditioning of $1$.<br>\n",
    "<br>\n",
    "So, locally in $x$, for a convex function, there exists a basis in which the function is well-conditioned and we would prefer to express the gradient in this basis in order to define a descent direction. It so happens (as said in the previous paragraph) that the basis-change matrix for such a change of coordinates is precisely the Hessian in $x$.<br>\n",
    "<br>\n",
    "The idea of the Conjugate Gradients method is to take successive descent directions that, instead of being orthogonal to each other in the standard coordinate system ($d_k^Td_{k+1} = 0$) are orthogonal to each other in the basis spanned by the columns of the Hessian $H$ in $x$, that is $d_k^THd_{k+1} = 0$.<br>\n",
    "<br>\n",
    "Such descent directions are said to be $H$-conjugate. The property of the Conjugate Gradients method is that it adapts to the local shape of the function. One can prove that by taking successive conjugate descent directions, one finally reaches the function's minimum. In practice, we can expect the Conjugate Gradients method to converge faster than plain gradient descent precisely because it avoids the \"bouncing phenomenon\" on the function's contour lines.<br>\n",
    "<br>\n",
    "To simplify the notations, from now on, we shall write $g_k = \\nabla_x f(x_k)$ the function's gradient in point $x_k$.<br>\n",
    "<br>\n",
    "In practice, one wants to avoid computing the Hessian at each step to find the next descent direction. Because the sequence of gradients generated by line search are orthogonal to each other, finding the current descent direction $d_k$ that is $H$-conjugate to all previous descent directions, can actually be simplified to an iterative formula that only requires the knowledge of the current gradient $g_k$ and the previous descent direction $d_{k-1}$.<br>\n",
    "<br>\n",
    "In the case of quadratic functions (constant Hessian), the consecutive descent directions are generated by:\n",
    "$$d_{k} = -g_k + \\frac{\\left(g_k\\right)^T g_k}{(g_{k-1})^Tg_{k-1}} d_{k-1}$$\n",
    "\n",
    "In the general case, Conjugate Gradients methods incrementally construct the sequence of descent directions using the Fletcher-Reeves or the Polak-RibiÃ¨re formula. The later is the most commonly used one:\n",
    "$$d_{k} = -g_k + \\frac{\\left(g_k\\right)^T \\left(g_k - g_{k-1} \\right)}{(g_{k-1})^Tg_{k-1}} d_{k-1}$$\n",
    "<br>\n",
    "Recall that as previously, in a Conjugate Gradient method, the step-size is found by line search.<br>\n",
    "<br>\n",
    "Implementing a Conjugate Gradients method can be a little tedious and we won't have the time during this class to do it. However, `scipy.optimize` provides a [`fmin_cg`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html) function (which is actually equivalent to calling the function [`minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) with the argument `method='CG'`). Run the code below to see the descent performed by the CG method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:26:55.706176Z",
     "start_time": "2019-02-15T10:26:55.232941Z"
    }
   },
   "outputs": [],
   "source": [
    "x0 = np.array([-5, -4])\n",
    "res = sopt.fmin_cg(func, x0, fprime=func_der, retall=True, disp=True)\n",
    "xopt = res[0]\n",
    "steps = np.array(res[1])\n",
    "\n",
    "print(steps)\n",
    "\n",
    "X0 = np.arange(-6, 6, 0.1)\n",
    "X1 = np.arange(-6, 6, 0.1)\n",
    "levels = np.array([0.15, 0.2, 0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "fig, ax = plot_contours_func(\n",
    "    func,\n",
    "    X0,\n",
    "    X1,\n",
    "    levels=levels,\n",
    "    xp=steps.T,\n",
    "    plot_line=True,\n",
    "    add_levels=False,\n",
    "    f_der=func_der,\n",
    ")\n",
    "clean_axis(ax)\n",
    "\n",
    "X0 = np.arange(-2.99, -2.98, 0.001)\n",
    "X1 = np.arange(-1.726, -1.720, 0.001)\n",
    "fig, ax = plot_contours_func(\n",
    "    func, X0, X1, xp=steps[4:, :].T, plot_line=True, add_levels=False, f_der=func_der\n",
    ")\n",
    "clean_axis(ax, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice something unexpected between the 3rd and 4th point?\n",
    "\n",
    "Yes indeed! It seems the line search procedure did not really find a minimum and went way too far. Actually, it seems to happen also between the 1st and 2nd point, where, this time it did not go as far as expected. That's because [`fmin_cg`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html) performs the line search using [Wolfe conditions](https://en.wikipedia.org/wiki/Wolfe_conditions), which define stopping conditions for performing *inexact line search*. Inexact line search methods provide an efficient way of computing an acceptable step length $\\alpha$ that reduces the objective function 'sufficiently', rather than minimizing the objective function over $\\alpha\\in \\mathbb{B}^+$ exactly. So it is simply a matter of tradeoff between computational time and line search accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercice:</b> Given all the experiments carried out in this section, with the same function and the same initialization of the search, fill the \"number of steps before convergence\" column in the table below.\n",
    "</div>\n",
    "\n",
    "| Algorithm                              | Number of steps before convergence |\n",
    "|----------------------------------------|------------------------------------|\n",
    "| Gradient descent with fixed step sizes | $\\sim30$                           |\n",
    "| Gradient descent with line search      | $10$                               |\n",
    "| Conjugate gradients with line search   | $2$                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Exercice:</b>\n",
    "How many steps does it take to a conjugate gradients method to converge on the quadratic, ill-conditioned $f_1(x_0,x_1) = x_0^2+10x_1^2$ function?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T10:27:33.733385Z",
     "start_time": "2019-02-15T10:27:33.434356Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/code5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Let's wrap everything up.</b>\n",
    "    <br/>In this section we have focused on gradient descent methods. We have seen that:\n",
    "<ol>\n",
    "<li> Descent methods define a sequence $x_{k+1} = x_k + \\alpha_k d_k$, where $d_k$ is a descent direction and $\\alpha_k$ is the step size.\n",
    "<li> The opposite of the gradient gives a descent direction.\n",
    "<li> The step size needs to be adapted to guarantee convergence. For this, we introduced line search and its properties.\n",
    "<li> The conjugate gradients method takes descent directions that account for the local shape (convexity, conditioning) of the function and converge faster.\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
